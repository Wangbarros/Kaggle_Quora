{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.probability import FreqDist\n",
    "import statsmodels.api as sm\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#nltk.download() #<---Use this command to download WordNet in corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"/media/fexunexa/Tree/Kaggle/Git Quora/data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Vendo as 3 primeiras informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Selecionando linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Selecionando Coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    What is the easiest way to become a billionair...\n",
       "201    Are there People who are willing to give free ...\n",
       "202      What's the best way to start learning robotics?\n",
       "203                  Why do people hate Hillary Clinton?\n",
       "204    Why are women who are on their periods are reg...\n",
       "Name: question1, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question1'][200:205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Selecionar duas colunas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "5  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "\n",
       "                                           question2  \n",
       "1  What would happen if the Indian government sto...  \n",
       "2  How can Internet speed be increased by hacking...  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...  \n",
       "4            Which fish would survive in salt water?  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.loc[1:5,['question1','question2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Selecionando pela posição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid2                                          question1\n",
       "1     4  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2     6  How can I increase the speed of my internet co...\n",
       "3     8  Why am I mentally very lonely? How can I solve...\n",
       "4    10  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[1:5,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Selecionando informação específica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149263, 6)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.is_duplicate == 1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Verificando por vazios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vazioQ1 = []\n",
    "vazioQ2 = []\n",
    "\n",
    "for i in range(0,len(train.question2)):\n",
    "    if type(train.question2[i]) is float:\n",
    "        vazioQ2.append(i)\n",
    "    if type(train.question1[i]) is float:\n",
    "        vazioQ1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] [105780, 201841]\n"
     ]
    }
   ],
   "source": [
    "print(vazioQ1, vazioQ2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Lower Case and removing punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lower_rm_punct(phrase):\n",
    "    if type(phrase) is not float:\n",
    "        phrase = phrase.lower()\n",
    "        phrase = phrase.translate(str.maketrans('','', string.punctuation))\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train.question1 = train.question1.apply(lambda x: lower_rm_punct(x))\n",
    "train.question2 = train.question2.apply(lambda x: lower_rm_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Function to Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def rm_stopwords(phrase):\n",
    "    stop = set(stopwords.words('english'))\n",
    "    \n",
    "    if type(phrase) is not float:\n",
    "        phrase = [i for i in phrase.split() if i not in stop]\n",
    "        phrase = ' '.join(phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_stopw = train\n",
    "\n",
    "train_stopw.question1 = train.question1.apply(lambda x: rm_stopwords(x))\n",
    "train_stopw.question2 = train.question2.apply(lambda x: rm_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Function to \"stem\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### From Stackoverflow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "##### At the very basics of it, the major difference between the porter and lancaster stemming algorithms is that the lancaster stemmer is significantly more aggressive than the porter stemmer. The three major stemming algorithms in use today are Porter, Snowball(Porter2), and Lancaster (Paice-Husk), with the aggressiveness continuum basically following along those same lines. Porter is the least aggressive algorithm, with the specifics of each algorithm actually being fairly lengthy and technical. Here is a break down for you though:\n",
    "\n",
    "##### Porter: Most commonly used stemmer without a doubt, also one of the most gentle stemmers. One of the few stemmers that actually has Java support which is a plus, though it is also the most computationally intensive of the algorithms(Granted not by a very significant margin). It is also the oldest stemming algorithm by a large margin.\n",
    "\n",
    "##### Porter2: Nearly universally regarded as an improvement over porter, and for good reason. Porter himself in fact admits that it is better than his original algorithm. Slightly faster computation time than porter, with a fairly large community around it.\n",
    "\n",
    "##### Lancaster: Very aggressive stemming algorithm, sometimes to a fault. With porter and snowball, the stemmed representations are usually fairly intuitive to a reader, not so with Lancaster, as many shorter words will become totally obfuscated. The fastest algorithm here, and will reduce your working set of words hugely, but if you want more distinction, not the tool you would want.\n",
    "\n",
    "##### Honestly, I feel that Snowball is usually the way to go. There are certain circumstances in which Lancaster will hugely trim down your working set, which can be very useful, however the marginal speed increase over snowball in my opinion is not worth the lack of precision. Porter has the most implementations though and so is usually the default go-to algorithm, but if you can, use snowball.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def stem_lancaster(phrase):\n",
    "    LS = LancasterStemmer()\n",
    "    \n",
    "    if type(phrase) is not float:\n",
    "        phrase = [LS.stem(i) for i in phrase.split()]\n",
    "        phrase = ' '.join(phrase)\n",
    "    return phrase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Function to \"lemmatize\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def lemm_wordnet(phrase):\n",
    "    lemm = WordNetLemmatizer()\n",
    "\n",
    "    if type(phrase) is not float:\n",
    "        phrase = [lemm.lemmatize(i) for i in phrase.split()]\n",
    "        phrase = ' '.join(phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Some Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def freq_all_text(question1,question2): #Pass all question\n",
    "\n",
    "    question1_freq = []\n",
    "    question2_freq = []\n",
    "    for i in range(0,len(question1)):\n",
    "        question1_freq += question1[i].split()\n",
    "        question2_freq += str(question2[i]).split()\n",
    "    \n",
    "    len_question_freq = len(set(question1_freq + question2_freq))\n",
    "    \n",
    "    question1_freq = FreqDist(question1_freq)\n",
    "    question2_freq = FreqDist(question2_freq)\n",
    "\n",
    "    return question1_freq, question2_freq, len_question_freq\n",
    "\n",
    "def percentage_by_text(phrase1, phrase2, question1_freq, question2_freq, len_question_freq):\n",
    "    phrase2 = str(phrase2)\n",
    "    \n",
    "    for i in range(0, len(phrase1)):\n",
    "            less_common_phrase1 = [i for i in set(phrase1.split()) if i not in phrase2.split()]\n",
    "            less_common_phrase2 = [i for i in set(phrase2.split()) if i not in phrase1.split()]\n",
    "            \n",
    "    freq_less_common_phrase1 = 0\n",
    "    freq_less_common_phrase2 = 0\n",
    "            \n",
    "    for i in less_common_phrase1:\n",
    "        freq_less_common_phrase1 += question1_freq[i]\n",
    "    \n",
    "    freq_less_common_phrase1 = freq_less_common_phrase1/len_question_freq\n",
    "    \n",
    "    for i in less_common_phrase2:\n",
    "        freq_less_common_phrase2 += question2_freq[i]\n",
    "    \n",
    "    freq_less_common_phrase2 = freq_less_common_phrase2/len_question_freq\n",
    "    \n",
    "    if freq_less_common_phrase1 == 0:\n",
    "        return freq_less_common_phrase2\n",
    "    \n",
    "    elif freq_less_common_phrase2 == 0:\n",
    "        return freq_less_common_phrase1\n",
    "    \n",
    "    elif freq_less_common_phrase1 >= freq_less_common_phrase2:\n",
    "        return freq_less_common_phrase2\n",
    "    \n",
    "    else:\n",
    "        return freq_less_common_phrase1\n",
    "\n",
    "def percentages_by_phrase(phrase1,phrase2):\n",
    "    phrase2 = str(phrase2)\n",
    "    \n",
    "    #Percentage between numbers of words\n",
    "    if len(phrase1.split()) >= len(phrase2.split()):\n",
    "        dif_wdsize = len(phrase2.split())/len(phrase1.split())\n",
    "    else:\n",
    "        dif_wdsize = len(phrase1.split())/len(phrase2.split())\n",
    "   \n",
    "    #Percentage between numbers of letters\n",
    "    if len(phrase1) >= len(phrase2):\n",
    "        dif_ltsize = len(phrase2)/len(phrase1)\n",
    "    else:\n",
    "        dif_ltsize = len(phrase1)/len(phrase2)\n",
    "        \n",
    "    #Percentage between letters and words per phrase\n",
    "    dif_ltwdsize = (len(phrase1.split())/len(phrase1))/(len(phrase2.split())/len(phrase2))\n",
    "\n",
    "    #Percentage of equal words\n",
    "    equal = [i for i in set(phrase1.split()) if i in set(phrase2.split())]\n",
    "    equal = ' '.join(equal)\n",
    "    \n",
    "    unique = set((phrase1 + ' ' + phrase2).split()) #Counting all unique words between the 2 phrases\n",
    "    unique = ' '.join(unique)\n",
    "    \n",
    "    perc_equal_w = len(equal)/len(unique)\n",
    "    \n",
    "    return dif_wdsize, dif_ltsize, dif_ltwdsize, perc_equal_w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train = train[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Saving some new informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(train.question1)):\n",
    "    p_size_word, p_size_letters, p_word_letters, p_equal_w = percentages_by_phrase(train.loc[i,'question1'],train.loc[i,'question2'])\n",
    "    \n",
    "    train.loc[i, 'p_size_word'] = p_size_word\n",
    "    train.loc[i, 'p_size_letters'] = p_size_letters\n",
    "    train.loc[i, 'p_word_letters'] = p_word_letters\n",
    "    train.loc[i, 'p_equal_w'] = p_equal_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "question1_freq, question2_freq, len_question_freq = freq_all_text(train.question1,train.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for i in range(0, len(train.question1)):\n",
    "    \n",
    "    p_less_common = percentage_by_text(train.loc[i,'question1'],train.loc[i,'question2'], question1_freq, question2_freq, len_question_freq)\n",
    "    \n",
    "    train.loc[i, 'p_less_common'] = p_less_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.611042\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>is_duplicate</td>   <th>  No. Observations:  </th>  <td>   300</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   297</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Mon, 20 Mar 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.08422</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>02:30:23</td>     <th>  Log-Likelihood:    </th> <td> -183.31</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -200.17</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>4.774e-08</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p_less_common</th>  <td>   -2.1223</td> <td>    3.207</td> <td>   -0.662</td> <td> 0.508</td> <td>   -8.407</td> <td>    4.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p_equal_w</th>      <td>    2.6621</td> <td>    0.582</td> <td>    4.571</td> <td> 0.000</td> <td>    1.521</td> <td>    3.803</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>p_word_letters</th> <td>   -1.3403</td> <td>    0.335</td> <td>   -3.998</td> <td> 0.000</td> <td>   -1.997</td> <td>   -0.683</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:           is_duplicate   No. Observations:                  300\n",
       "Model:                          Logit   Df Residuals:                      297\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Mon, 20 Mar 2017   Pseudo R-squ.:                 0.08422\n",
       "Time:                        02:30:23   Log-Likelihood:                -183.31\n",
       "converged:                       True   LL-Null:                       -200.17\n",
       "                                        LLR p-value:                 4.774e-08\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "p_less_common     -2.1223      3.207     -0.662      0.508      -8.407       4.162\n",
       "p_equal_w          2.6621      0.582      4.571      0.000       1.521       3.803\n",
       "p_word_letters    -1.3403      0.335     -3.998      0.000      -1.997      -0.683\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(train['is_duplicate'], train.loc[:,['p_less_common','p_equal_w','p_word_letters']])\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p_less_common</th>\n",
       "      <td>-8.407121</td>\n",
       "      <td>4.162432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_equal_w</th>\n",
       "      <td>1.520682</td>\n",
       "      <td>3.803491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p_word_letters</th>\n",
       "      <td>-1.997304</td>\n",
       "      <td>-0.683256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0         1\n",
       "p_less_common  -8.407121  4.162432\n",
       "p_equal_w       1.520682  3.803491\n",
       "p_word_letters -1.997304 -0.683256"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.735484\n",
       "1      0.326307\n",
       "2      0.265023\n",
       "3      0.099993\n",
       "4      0.318818\n",
       "5      0.375550\n",
       "6      0.146736\n",
       "7      0.308781\n",
       "8      0.610755\n",
       "9      0.383125\n",
       "10     0.200228\n",
       "11     0.456504\n",
       "12     0.609740\n",
       "13     0.721750\n",
       "14     0.739665\n",
       "15     0.285728\n",
       "16     0.594740\n",
       "17     0.171516\n",
       "18     0.352996\n",
       "19     0.540069\n",
       "20     0.316021\n",
       "21     0.409747\n",
       "22     0.335203\n",
       "23     0.083871\n",
       "24     0.155671\n",
       "25     0.606983\n",
       "26     0.510538\n",
       "27     0.308631\n",
       "28     0.644329\n",
       "29     0.373665\n",
       "         ...   \n",
       "270    0.733909\n",
       "271    0.294089\n",
       "272    0.205795\n",
       "273    0.288837\n",
       "274    0.513602\n",
       "275    0.397372\n",
       "276    0.192514\n",
       "277    0.680053\n",
       "278    0.391363\n",
       "279    0.366511\n",
       "280    0.208913\n",
       "281    0.367054\n",
       "282    0.289876\n",
       "283    0.123947\n",
       "284    0.446840\n",
       "285    0.429860\n",
       "286    0.422897\n",
       "287    0.643417\n",
       "288    0.364285\n",
       "289    0.402311\n",
       "290    0.730083\n",
       "291    0.639781\n",
       "292    0.272389\n",
       "293    0.600580\n",
       "294    0.277196\n",
       "295    0.472287\n",
       "296    0.381659\n",
       "297    0.125428\n",
       "298    0.753771\n",
       "299    0.436974\n",
       "dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.predict(train.loc[:,['p_less_common','p_equal_w','p_word_letters']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
