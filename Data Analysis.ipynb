{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import re\n",
    "import pickle\n",
    "import logging\n",
    "import string\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_auc_score as AUC\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "from gensim import similarities\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/chenwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "quora_train = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   id  qid1  qid2                                          question1  \\\n",
      "0   0     1     2  What is the step by step guide to invest in sh...   \n",
      "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
      "2   2     5     6  How can I increase the speed of my internet co...   \n",
      "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
      "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
      "\n",
      "                                           question2  is_duplicate  \n",
      "0  What is the step by step guide to invest in sh...             0  \n",
      "1  What would happen if the Indian government sto...             0  \n",
      "2  How can Internet speed be increased by hacking...             0  \n",
      "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
      "4            Which fish would survive in salt water?             0  \n"
     ]
    }
   ],
   "source": [
    "print (type(quora_train))\n",
    "print(quora_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Functions to process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'step step guid invest share market india'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Editing questions with NLTK package\n",
    "\n",
    "def remove_stopwords(phrase,list_stopwords):\n",
    "    \n",
    "    final_phrase = []\n",
    "    words = phrase.split(\" \")\n",
    "    for word in words:\n",
    "        if word not in list_stopwords:\n",
    "            final_phrase.append((word))\n",
    "    \n",
    "    final_phrase = ' '.join(final_phrase)\n",
    "    \n",
    "    return final_phrase\n",
    "    \n",
    "def remove_punctuation(phrase):\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    phrase = phrase.translate(translator) #removing punctuation\n",
    "    \n",
    "    \n",
    "    if type(phrase) is float:\n",
    "        if math.isnan(phrase):\n",
    "            return (\"\")\n",
    "        \n",
    "    return phrase\n",
    "\n",
    "def lemm_wordnet(phrase):\n",
    "    \"\"\"\n",
    "    Lemmatize using WordNetâ€™s built-in morphy function. \n",
    "    Returns the input word unchanged if it cannot be found in WordNet\n",
    "    \"\"\"\n",
    "    lemm = WordNetLemmatizer()\n",
    "    \n",
    "    #NA is a float type, so this if is to avoid conflict\n",
    "    if type(phrase) is not float:\n",
    "        phrase = [lemm.lemmatize(i) for i in phrase.split()]\n",
    "        phrase = ' '.join(phrase)\n",
    "    return phrase\n",
    "    \n",
    "\n",
    "def stem_stopwords_punctuation_case (phrase):\n",
    "    \"\"\"\n",
    "    Receives a phrase and returns the same phrase stemmed, lowercase phrase without stopwords\n",
    "    :param package_name: String. A phrase.\n",
    "    :return: String. Stemmed, lowercase phrase without stopwords\n",
    "    \"\"\"\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    phrase = remove_punctuation(phrase)\n",
    "    phrase = phrase.lower() #removing word case\n",
    "    phrase = remove_stopwords(phrase,stopwords)\n",
    "    \n",
    "    #Stem words according to stemmer\n",
    "    final_phrase = []\n",
    "    words = phrase.split(\" \")\n",
    "    for word in words:\n",
    "        final_phrase.append((stemmer.stem(word)))\n",
    "    \n",
    "    final_phrase = ' '.join(final_phrase)\n",
    "    \n",
    "    return final_phrase\n",
    "\n",
    "stem_stopwords_punctuation_case(\n",
    "    \"What is the step by step guide to invest in share market in india?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quora_train[\"question1_edited\"] = quora_train[\"question1\"].apply(lambda x: stem_stopwords_punctuation_case(x))\n",
    "quora_train[\"question2_edited\"] = quora_train[\"question2\"].apply(lambda x: stem_stopwords_punctuation_case(x))\n",
    "\n",
    "print (quora_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Store edited databases w/ Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"Edited_Base_stem_stopwords\",'wb') \n",
    "pickle.dump(quora_train,fileObject)  \n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fileObject = open(\"Edited_Base_stem_stopwords\",'rb')  \n",
    "quora_train = pickle.load(fileObject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_common_percentage(df):\n",
    "    \"\"\"\n",
    "    Receives the initial data frame and adds  the colunms \"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "    :param package_name: Data frame train.csv from the Kaggle website\n",
    "    :return: Data frame with added colunms \"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "    \"\"\"\n",
    "\n",
    "    num_words_common = []\n",
    "    num_words_total = []\n",
    "\n",
    "    for line in range(0,len(df)):\n",
    "        count_total = 0\n",
    "        count_common = 0\n",
    "        for word in df[\"question1_edited\"][line].split(\" \"):\n",
    "            if word in df[\"question2_edited\"][line]:\n",
    "                count_common = count_common+1\n",
    "            count_total = count_total+1\n",
    "        num_words_common.append(count_common) \n",
    "        num_words_total.append(count_total)\n",
    "\n",
    "    num_words_common = pd.Series(num_words_common)\n",
    "    num_words_total = pd.Series(num_words_total)\n",
    "\n",
    "    df[\"num_words_common\"] = num_words_common.values\n",
    "    df[\"num_words_total\"] = num_words_total.values\n",
    "    df[\"common_percentage\"] = df[\"num_words_common\"]/df[\"num_words_total\"]\n",
    "\n",
    "    return (df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quora_train = calculate_common_percentage(quora_train)\n",
    "#\"num_words_common\", \"num_words_total\" and \"common_percentage\"\n",
    "plt.figure()\n",
    "#plt.boxplot(quora_train[\"common_percentage\"],quora_train[\"is_duplicate\"])\n",
    "\n",
    "\n",
    "quora_train.boxplot(column='common_percentage', by='is_duplicate')\n",
    "plt.suptitle('')\n",
    "\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([-0.2,1.1])\n",
    "plt.title(\"Common word percentage and is_duplicate\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
